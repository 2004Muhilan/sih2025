	.file	"sha256_compress.c"
	.option pic
	.attribute arch, "rv64i2p1_m2p0_a2p1_f2p2_d2p2_c2p0_zicsr2p0_zifencei2p0"
	.attribute unaligned_access, 0
	.attribute stack_align, 16
	.text
	.align	1
	.globl	sha256_compress
	.type	sha256_compress, @function
sha256_compress:
.LFB0:
	.cfi_startproc
	addi	sp,sp,-432
	.cfi_def_cfa_offset 432
	addi	a4,sp,56
	sd	s0,416(sp)
	.cfi_offset 8, -16
	mv	s0,a0
	mv	a0,a4
	la	a4,__stack_chk_guard
	li	a2,64
	ld	a5, 0(a4)
	sd	a5, 312(sp)
	li	a5, 0
	sd	s11,328(sp)
	sd	ra,424(sp)
	sd	s1,408(sp)
	sd	s2,400(sp)
	sd	s3,392(sp)
	sd	s4,384(sp)
	sd	s5,376(sp)
	sd	s6,368(sp)
	sd	s7,360(sp)
	sd	s8,352(sp)
	sd	s9,344(sp)
	sd	s10,336(sp)
	.cfi_offset 27, -104
	.cfi_offset 1, -8
	.cfi_offset 9, -24
	.cfi_offset 18, -32
	.cfi_offset 19, -40
	.cfi_offset 20, -48
	.cfi_offset 21, -56
	.cfi_offset 22, -64
	.cfi_offset 23, -72
	.cfi_offset 24, -80
	.cfi_offset 25, -88
	.cfi_offset 26, -96
	call	memcpy@plt
	mv	a4,a0
	lw	t4,92(sp)
	lw	a3,96(sp)
	lw	t1,100(sp)
	lw	a7,104(sp)
	lw	a0,108(sp)
	lw	a6,112(sp)
	lw	a1,116(sp)
	lw	a2,56(sp)
	mv	t3,a4
	li	s11,16
	sd	a4,8(sp)
.L2:
	lw	s1,4(t3)
	srliw	s2,a6,17
	srliw	t2,a6,19
	slliw	s4,s1,25
	srliw	s3,s1,18
	slliw	t5,a6,15
	slliw	t6,a6,13
	srliw	a5,s1,7
	slliw	t0,s1,14
	or	t0,t0,s3
	or	t6,t6,t2
	or	a5,a5,s4
	or	t5,t5,s2
	srliw	t2,a6,10
	srliw	s2,s1,3
	xor	a5,a5,t0
	xor	t5,t5,t6
	lw	t0,12(t3)
	xor	t5,t5,t2
	xor	a5,a5,s2
	lw	t2,8(t3)
	addw	a5,a5,t5
	addw	a5,a5,a2
	addw	t4,a5,t4
	srliw	s3,a1,19
	srliw	t6,a1,17
	srliw	s2,t0,18
	slliw	t5,t0,25
	slliw	s5,a1,13
	slliw	a2,a1,15
	slliw	s4,t0,14
	srliw	a5,t0,7
	or	s5,s5,s3
	srliw	s9,t2,7
	or	s4,s4,s2
	or	a2,a2,t6
	slliw	s10,t2,14
	srliw	s3,t2,18
	slliw	t6,t2,25
	or	a5,a5,t5
	slliw	s7,t4,15
	srliw	t5,t4,19
	slliw	s8,t4,13
	srliw	s2,t4,17
	srliw	s6,a1,10
	or	s2,s7,s2
	xor	a2,s5,a2
	or	s3,s10,s3
	or	t6,s9,t6
	xor	a5,s4,a5
	srliw	s9,t0,3
	or	s8,s8,t5
	lw	s5,16(t3)
	lw	s4,20(t3)
	xor	a2,a2,s6
	xor	s8,s8,s2
	xor	t6,s3,t6
	xor	a5,a5,s9
	srliw	s3,t2,3
	srliw	s2,t4,10
	addw	t5,a2,s1
	xor	t6,t6,s3
	xor	a2,s8,s2
	addw	a5,a5,t2
	addw	a5,a5,a2
	addw	t5,t5,t6
	addw	t5,t5,a3
	addw	t1,a5,t1
	srliw	s3,s5,18
	slliw	s1,s5,25
	slliw	s2,s5,14
	srliw	t6,s5,7
	slliw	t2,s4,25
	srliw	a2,s4,18
	srliw	a5,s4,7
	slliw	a3,s4,14
	or	t6,t6,s1
	or	a3,a3,a2
	or	s2,s2,s3
	srliw	s9,t5,19
	srliw	s7,t5,17
	or	a5,a5,t2
	srliw	s8,t1,17
	srliw	a2,t1,19
	slliw	s6,t5,13
	slliw	s1,t5,15
	slliw	t2,t1,15
	slliw	s3,t1,13
	xor	s2,s2,t6
	or	s6,s6,s9
	or	s3,s3,a2
	srliw	t6,s5,3
	or	s1,s1,s7
	xor	a5,a5,a3
	srliw	s7,s4,3
	or	t2,t2,s8
	lw	a3,24(t3)
	lw	a2,28(t3)
	xor	t2,t2,s3
	xor	t6,s2,t6
	xor	s1,s6,s1
	srliw	s2,t5,10
	xor	a5,a5,s7
	srliw	s3,t1,10
	xor	s1,s1,s2
	addw	t6,t6,t0
	addw	a5,a5,s5
	xor	t0,t2,s3
	addw	t6,t6,s1
	addw	a5,a5,t0
	addw	a5,a5,a0
	addw	a7,t6,a7
	slliw	s2,a3,25
	srliw	t6,a3,18
	srliw	t2,a3,7
	slliw	s5,a3,14
	slliw	s6,a2,25
	srliw	a0,a2,18
	srliw	t0,a2,7
	slliw	s1,a2,14
	or	s5,s5,t6
	or	s1,s1,a0
	or	t2,t2,s2
	srliw	s3,a7,19
	or	t0,t0,s6
	slliw	a0,a5,15
	srliw	s8,a5,17
	slliw	s7,a5,13
	srliw	s6,a5,19
	slliw	t6,a7,15
	srliw	s9,a7,17
	slliw	s2,a7,13
	or	s2,s2,s3
	xor	t2,t2,s5
	xor	t0,t0,s1
	srliw	s5,a3,3
	or	a0,a0,s8
	or	s1,s7,s6
	or	t6,t6,s9
	srliw	s3,a2,3
	addw	a1,a1,a3
	xor	t6,t6,s2
	xor	a3,a0,s1
	addw	a6,a6,s4
	srliw	s1,a5,10
	xor	t2,t2,s5
	srliw	s2,a7,10
	xor	t0,t0,s3
	xor	a0,t6,s2
	xor	a3,a3,s1
	addw	a6,a6,t2
	addw	a1,a1,t0
	addw	a6,a6,a0
	addw	a1,a1,a3
	sw	a5,80(t3)
	sw	t4,64(t3)
	sw	t5,68(t3)
	sw	t1,72(t3)
	sw	a7,76(t3)
	sw	a6,84(t3)
	sw	a1,88(t3)
	sext.w	a0,a5
	addiw	s11,s11,7
	li	a5,58
	sext.w	a3,t5
	addi	t3,t3,28
	bne	s11,a5,.L2
	lw	t3,228(sp)
	lw	t0,280(sp)
	lw	t4,232(sp)
	lw	a2,284(sp)
	lw	s2,260(sp)
	srliw	a7,t3,18
	slliw	a1,t3,25
	lw	t1,224(sp)
	slliw	a6,t3,14
	srliw	a3,t3,7
	or	a3,a3,a1
	srliw	s4,t0,19
	srliw	s3,t0,17
	srliw	t2,t4,18
	slliw	t6,t4,25
	lw	a0,264(sp)
	or	a6,a6,a7
	slliw	s1,t0,15
	slliw	a7,t0,13
	slliw	a1,t4,14
	srliw	t5,t4,7
	srliw	s5,t3,3
	or	s1,s1,s3
	or	t5,t5,t6
	srliw	s3,a2,19
	xor	a6,a6,a3
	or	a7,a7,s4
	or	a1,a1,t2
	srliw	s4,a2,17
	slliw	a3,a2,15
	slliw	t6,a2,13
	lw	t2,240(sp)
	addw	t1,t1,s2
	or	t6,t6,s3
	srliw	s2,t0,10
	xor	a6,a6,s5
	xor	a7,a7,s1
	xor	a1,a1,t5
	srliw	s1,t4,3
	or	a3,a3,s4
	lw	t5,236(sp)
	xor	a7,a7,s2
	xor	a1,a1,s1
	addw	a6,t1,a6
	addw	a0,a0,t3
	xor	a3,a3,t6
	srliw	a2,a2,10
	addw	a6,a6,a7
	xor	a3,a3,a2
	addw	a0,a0,a1
	addw	a0,a0,a3
	slliw	a7,t2,25
	srliw	a3,t2,18
	lw	a1,268(sp)
	lw	a2,272(sp)
	srliw	t3,a6,17
	srliw	t1,a6,19
	srliw	s5,t2,7
	slliw	t6,t2,14
	slliw	s1,a6,15
	slliw	s2,a6,13
	or	s2,s2,t1
	slliw	s9,t5,25
	slliw	s8,t5,14
	or	s5,s5,a7
	slliw	s7,a0,15
	slliw	s6,a0,13
	or	s1,s1,t3
	srliw	s4,t5,18
	srliw	t3,t5,7
	or	t6,t6,a3
	srliw	t1,a0,17
	srliw	s3,a0,19
	lw	a3,244(sp)
	lw	a7,248(sp)
	xor	s1,s1,s2
	or	s4,s8,s4
	xor	t6,s5,t6
	or	s3,s6,s3
	srliw	s5,t2,3
	or	t3,t3,s9
	or	t1,s7,t1
	srliw	s2,a6,10
	xor	s2,s1,s2
	addw	a1,a1,t4
	srliw	s1,t5,3
	xor	t4,t6,s5
	xor	t3,t3,s4
	addw	a2,a2,t5
	xor	t1,t1,s3
	srliw	t5,a0,10
	xor	t3,t3,s1
	xor	t1,t1,t5
	addw	a1,a1,s2
	addw	a2,a2,t4
	addw	a1,a1,t3
	addw	a2,a2,t1
	slliw	s4,a3,25
	srliw	t6,a3,18
	slliw	s1,a7,25
	srliw	t5,a7,18
	lw	t1,276(sp)
	srliw	s3,a3,7
	slliw	t4,a3,14
	srliw	s2,a7,7
	slliw	t3,a7,14
	or	t4,t4,t6
	srliw	s6,a1,17
	srliw	s5,a1,19
	or	t3,t3,t5
	or	s3,s3,s4
	slliw	s11,a1,15
	slliw	t6,a1,13
	or	s2,s2,s1
	srliw	s4,a2,17
	srliw	s1,a2,19
	slliw	t5,a2,15
	slliw	s10,a2,13
	xor	s3,s3,t4
	srliw	s8,a3,3
	or	s11,s11,s6
	or	t6,t6,s5
	xor	s2,s2,t3
	srliw	a7,a7,3
	or	t5,t5,s4
	or	s10,s10,s1
	lw	s6,0(s0)
	lw	s5,4(s0)
	lw	s4,8(s0)
	xor	s8,s3,s8
	addw	t1,t1,t2
	xor	s2,s2,a7
	srliw	t2,a1,10
	addw	a3,t0,a3
	xor	t6,s11,t6
	srliw	t0,a2,10
	xor	t5,t5,s10
	lw	s9,16(s0)
	addw	a7,t1,s8
	lw	s7,12(s0)
	lw	t4,20(s0)
	lw	t3,24(s0)
	lw	s1,28(s0)
	xor	t6,t6,t2
	addw	a3,a3,s2
	xor	t1,t5,t0
	addw	a7,a7,t6
	addw	a3,a3,t1
	ld	a5,8(sp)
	sw	a0,292(sp)
	sw	a1,296(sp)
	sw	a7,304(sp)
	sw	a3,308(sp)
	li	s8,1116352512
	sw	a6,288(sp)
	sw	a2,300(sp)
	sd	s6,8(sp)
	sd	s5,16(sp)
	sd	s4,24(sp)
	sd	s7,32(sp)
	addi	a4,a4,256
	mv	a3,s1
	mv	s2,t3
	mv	t6,t4
	mv	a1,s9
	mv	s3,s7
	mv	t0,s4
	mv	a7,s5
	mv	a0,s6
	addiw	s8,s8,-104
	sd	s9,40(sp)
	j	.L3
.L5:
	mv	s2,t6
	mv	t0,a7
	mv	t6,a6
	mv	a1,s4
	mv	a7,t5
	mv	a0,t2
.L3:
	slliw	t5,a1,26
	slliw	a6,a1,21
	lw	a2,0(a5)
	srliw	s4,a1,6
	srliw	t1,a1,11
	srliw	s5,a1,25
	or	t1,t1,a6
	slliw	t2,a1,7
	or	s4,s4,t5
	xor	s4,s4,t1
	not	t5,a1
	or	t2,t2,s5
	and	s9,a1,t6
	xor	t2,s4,t2
	srliw	s11,a0,2
	slliw	s6,a0,30
	srliw	s10,a0,13
	slliw	a6,a0,19
	addw	a2,s8,a2
	and	t5,t5,s2
	slliw	s5,a0,10
	srliw	s7,a0,22
	xor	t1,a7,t0
	addw	a2,a2,t2
	xor	t5,t5,s9
	or	s6,s11,s6
	or	a6,s10,a6
	and	s4,a7,t0
	and	t1,a0,t1
	addw	a2,a2,t5
	xor	a6,s6,a6
	or	s5,s5,s7
	xor	t1,t1,s4
	addw	a2,a2,a3
	xor	a6,a6,s5
	addw	a6,a6,t1
	addw	s4,a2,s3
	sext.w	a1,a1
	sext.w	a0,a0
	addi	a5,a5,4
	addw	t2,a2,a6
	mv	t1,s4
	sext.w	t5,a0
	sext.w	a7,a7
	sext.w	s3,t0
	sext.w	a6,a1
	sext.w	t6,t6
	sext.w	a3,s2
	bne	a4,a5,.L5
	ld	s6,8(sp)
	ld	s5,16(sp)
	ld	s4,24(sp)
	ld	s7,32(sp)
	ld	s9,40(sp)
	addw	s6,s6,t2
	addw	s5,s5,a0
	addw	s4,s4,a7
	addw	s7,s7,t0
	addw	s9,s9,t1
	addw	t4,t4,a1
	addw	t3,t3,t6
	addw	s1,s1,s2
	la	a5,__stack_chk_guard
	sw	s6,0(s0)
	sw	s5,4(s0)
	sw	s4,8(s0)
	sw	s7,12(s0)
	sw	s9,16(s0)
	sw	t4,20(s0)
	sw	t3,24(s0)
	sw	s1,28(s0)
	ld	a4, 312(sp)
	ld	a5, 0(a5)
	xor	a5, a4, a5
	li	a4, 0
	bne	a5,zero,.L9
	ld	ra,424(sp)
	.cfi_remember_state
	.cfi_restore 1
	ld	s0,416(sp)
	.cfi_restore 8
	ld	s1,408(sp)
	.cfi_restore 9
	ld	s2,400(sp)
	.cfi_restore 18
	ld	s3,392(sp)
	.cfi_restore 19
	ld	s4,384(sp)
	.cfi_restore 20
	ld	s5,376(sp)
	.cfi_restore 21
	ld	s6,368(sp)
	.cfi_restore 22
	ld	s7,360(sp)
	.cfi_restore 23
	ld	s8,352(sp)
	.cfi_restore 24
	ld	s9,344(sp)
	.cfi_restore 25
	ld	s10,336(sp)
	.cfi_restore 26
	ld	s11,328(sp)
	.cfi_restore 27
	addi	sp,sp,432
	.cfi_def_cfa_offset 0
	jr	ra
.L9:
	.cfi_restore_state
	call	__stack_chk_fail@plt
	.cfi_endproc
.LFE0:
	.size	sha256_compress, .-sha256_compress
	.ident	"GCC: (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0"
	.section	.note.GNU-stack,"",@progbits
